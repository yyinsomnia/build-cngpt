{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hQNXuf1bv-q8"
      ],
      "authorship_tag": "ABX9TyP4/Ei1TPFW1sdNXedbfJ2y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yyinsomnia/build-cngpt/blob/main/play_gpt_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# init 环境和数据\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hQNXuf1bv-q8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Iih4-H2Qvq07"
      },
      "outputs": [],
      "source": [
        "# ! pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# play embd\n",
        "\n",
        "1. 首先还是要能learn的，不然就只有forward没有backward了"
      ],
      "metadata": {
        "id": "UiiUQAVswTAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 模拟一个batch的input\n",
        "vocab_size = 3758  # 3500个常用字 + 256个ASCII + 2个[UNK] [MASK]\n",
        "B, T = 8, 16\n",
        "\n",
        "shape = (8, 16, 1) # (B, T, id)\n",
        "token_ids = torch.randint(low=0, high=3758, size=shape)\n",
        "print(token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZw4qsuewRiH",
        "outputId": "34510622-c517-472a-dda6-662ae61ac05e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[2043],\n",
            "         [2214],\n",
            "         [1451],\n",
            "         [ 579],\n",
            "         [ 936],\n",
            "         [2471],\n",
            "         [ 613],\n",
            "         [2677],\n",
            "         [ 664],\n",
            "         [ 306],\n",
            "         [ 376],\n",
            "         [3455],\n",
            "         [3527],\n",
            "         [3383],\n",
            "         [3108],\n",
            "         [ 764]],\n",
            "\n",
            "        [[ 412],\n",
            "         [1935],\n",
            "         [ 415],\n",
            "         [2292],\n",
            "         [ 496],\n",
            "         [3198],\n",
            "         [2860],\n",
            "         [ 714],\n",
            "         [3599],\n",
            "         [2369],\n",
            "         [3043],\n",
            "         [3444],\n",
            "         [3077],\n",
            "         [2359],\n",
            "         [3374],\n",
            "         [2564]],\n",
            "\n",
            "        [[2548],\n",
            "         [ 414],\n",
            "         [ 839],\n",
            "         [2303],\n",
            "         [ 474],\n",
            "         [3002],\n",
            "         [ 984],\n",
            "         [ 693],\n",
            "         [1598],\n",
            "         [ 335],\n",
            "         [  42],\n",
            "         [1794],\n",
            "         [  21],\n",
            "         [2100],\n",
            "         [ 624],\n",
            "         [ 425]],\n",
            "\n",
            "        [[3013],\n",
            "         [ 616],\n",
            "         [3134],\n",
            "         [3440],\n",
            "         [1470],\n",
            "         [3730],\n",
            "         [2779],\n",
            "         [2204],\n",
            "         [3350],\n",
            "         [ 121],\n",
            "         [1855],\n",
            "         [1038],\n",
            "         [ 757],\n",
            "         [2131],\n",
            "         [2746],\n",
            "         [  13]],\n",
            "\n",
            "        [[3135],\n",
            "         [ 506],\n",
            "         [2141],\n",
            "         [1337],\n",
            "         [1139],\n",
            "         [ 571],\n",
            "         [1648],\n",
            "         [1403],\n",
            "         [ 529],\n",
            "         [3414],\n",
            "         [ 758],\n",
            "         [2747],\n",
            "         [3385],\n",
            "         [ 665],\n",
            "         [2556],\n",
            "         [1311]],\n",
            "\n",
            "        [[1287],\n",
            "         [ 680],\n",
            "         [3037],\n",
            "         [ 565],\n",
            "         [3462],\n",
            "         [2036],\n",
            "         [1005],\n",
            "         [3595],\n",
            "         [1768],\n",
            "         [ 966],\n",
            "         [3356],\n",
            "         [2834],\n",
            "         [2486],\n",
            "         [2653],\n",
            "         [ 289],\n",
            "         [1277]],\n",
            "\n",
            "        [[ 311],\n",
            "         [2144],\n",
            "         [3261],\n",
            "         [ 119],\n",
            "         [3382],\n",
            "         [2565],\n",
            "         [ 101],\n",
            "         [ 654],\n",
            "         [3720],\n",
            "         [2771],\n",
            "         [2611],\n",
            "         [2950],\n",
            "         [1311],\n",
            "         [3075],\n",
            "         [3126],\n",
            "         [3388]],\n",
            "\n",
            "        [[2851],\n",
            "         [1440],\n",
            "         [1599],\n",
            "         [1214],\n",
            "         [3269],\n",
            "         [ 724],\n",
            "         [2031],\n",
            "         [ 794],\n",
            "         [ 846],\n",
            "         [2286],\n",
            "         [2828],\n",
            "         [3029],\n",
            "         [2605],\n",
            "         [1207],\n",
            "         [1418],\n",
            "         [ 323]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 注意：这里的共3个维度，最后一维度也是向量。"
      ],
      "metadata": {
        "id": "4ORnwBdQ2evA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 第2个batch的第4个token，也是一个向量\n",
        "print(token_ids[1, 3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exYxWoqI2MIK",
        "outputId": "00cb809b-694a-4f16-bb5b-fc59b1972d15"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2292])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "embd_dim = 256\n",
        "\n",
        "embd = nn.Embedding(vocab_size, embd_dim)\n",
        "\n",
        "x = embd(token_ids)\n",
        "\n",
        "print(x.shape) # (B, T, C) C就是embd_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdBrIiwU36Uf",
        "outputId": "87c49905-a804-4ec8-ccfa-d827ad443dbb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 16, 1, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "发现shape和预期的不符合\n",
        "\n",
        "pytorch的docs里面\n",
        "Shape Input: (\\*) Output: (\\*, H)\n"
      ],
      "metadata": {
        "id": "Hk_NyIa3-dAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRXWKEiC5y1I",
        "outputId": "d5e21f64-8903-4313-9f1f-12db0e2279ef"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 1.1412,  1.4311, -1.5662,  ..., -0.9454,  0.7590,  1.8491]],\n",
              "\n",
              "         [[-1.3643, -1.7146,  0.9686,  ..., -0.4602,  2.1885,  0.7165]],\n",
              "\n",
              "         [[ 0.0306, -1.4302,  3.0268,  ...,  0.0419,  0.8861, -0.5051]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-0.0506, -0.6311, -1.1254,  ..., -0.2504, -0.2527,  0.0973]],\n",
              "\n",
              "         [[-0.9731,  0.6187,  1.3248,  ..., -1.3551, -1.4239, -0.4659]],\n",
              "\n",
              "         [[-0.5806,  1.2208,  0.7113,  ...,  1.8048,  1.2067, -1.8959]]],\n",
              "\n",
              "\n",
              "        [[[ 0.7007, -0.4798,  0.8899,  ...,  0.9325,  0.0791,  1.3326]],\n",
              "\n",
              "         [[ 1.2629,  1.8462, -0.7314,  ..., -0.5244, -0.5179,  0.8159]],\n",
              "\n",
              "         [[-1.5975, -0.2385, -0.3092,  ...,  0.6572, -0.5316, -0.8374]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 1.3551, -0.1080, -0.6651,  ...,  1.2770,  0.6605,  0.0426]],\n",
              "\n",
              "         [[-0.7347,  0.4656,  1.4997,  ...,  0.8134, -0.3868, -0.1720]],\n",
              "\n",
              "         [[-0.5680,  1.4662,  0.3667,  ...,  0.1219, -0.8770, -0.9035]]],\n",
              "\n",
              "\n",
              "        [[[-0.7831,  0.2401, -0.7243,  ..., -1.1168, -0.5934,  0.0601]],\n",
              "\n",
              "         [[ 1.5127, -0.5856,  0.8385,  ..., -1.1545, -0.1195,  0.8528]],\n",
              "\n",
              "         [[ 0.8131, -0.7501,  0.3397,  ..., -0.0167, -0.5613, -0.7761]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 1.0138,  1.2926,  1.7003,  ...,  1.1608,  2.4404,  0.7355]],\n",
              "\n",
              "         [[ 0.1867,  0.7329, -0.8327,  ..., -0.5140,  0.2337, -0.2039]],\n",
              "\n",
              "         [[-1.0072, -1.1137,  1.0769,  ..., -0.4987, -0.5314, -1.3917]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[-1.4426,  0.5780,  0.1545,  ..., -0.0758, -0.0128, -0.8955]],\n",
              "\n",
              "         [[ 0.5450, -0.1573,  0.5907,  ..., -0.8163, -1.2846,  0.1132]],\n",
              "\n",
              "         [[ 1.3250,  0.8227,  0.5407,  ...,  1.5588, -0.0130, -0.8237]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-3.0313,  0.4517, -0.1592,  ..., -0.6772, -0.3612, -0.3668]],\n",
              "\n",
              "         [[-0.8751, -0.7362, -1.1547,  ...,  0.3377,  0.2253, -0.7455]],\n",
              "\n",
              "         [[-0.0342, -2.1515,  0.5839,  ...,  1.1767, -0.8979, -0.4837]]],\n",
              "\n",
              "\n",
              "        [[[-1.3441,  1.2403,  0.4114,  ..., -1.7385,  0.1428,  0.0529]],\n",
              "\n",
              "         [[-0.8459, -1.6409, -0.2755,  ...,  0.0959,  1.6111, -1.9002]],\n",
              "\n",
              "         [[ 0.0163, -0.4347,  0.2352,  ..., -0.9663, -1.6129,  0.2696]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 0.5288,  0.5320,  0.1850,  ...,  0.5923, -0.1277, -0.5197]],\n",
              "\n",
              "         [[-1.6773,  0.4332,  0.5792,  ..., -1.2241,  2.4508,  1.1810]],\n",
              "\n",
              "         [[-0.6866, -1.0705, -0.4861,  ...,  0.2226,  2.5501,  1.7249]]],\n",
              "\n",
              "\n",
              "        [[[ 0.3212,  0.3853, -1.1566,  ...,  3.2877,  1.1026, -0.1438]],\n",
              "\n",
              "         [[ 0.1043,  0.0940,  0.3273,  ...,  0.5100,  0.7008, -0.3989]],\n",
              "\n",
              "         [[-0.7198, -1.2058,  1.9146,  ...,  1.4097, -0.9013,  1.1385]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 1.5834, -1.5549,  0.7789,  ..., -0.2953, -0.6341, -3.2824]],\n",
              "\n",
              "         [[ 0.7352, -0.1867, -0.1793,  ..., -0.4444, -0.3961, -2.1300]],\n",
              "\n",
              "         [[-0.4831,  0.1128,  0.3600,  ...,  1.3419,  1.0139,  0.8331]]]],\n",
              "       grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "仔细想一下是合理的。如果是图片，那有RGB 3个值，就变成了(B, H, W, 3)\n",
        "这样RGB每个过完embd，应该是变成了(B, H, W, 3, embd_dim)"
      ],
      "metadata": {
        "id": "oATsRJZOAg2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 简单一点把最后一维弄成标量看看\n",
        "shape = (8, 16,)\n",
        "token_ids = torch.randint(low=0, high=vocab_size, size=shape)\n",
        "print(token_ids)\n",
        "# 这个输出是熟悉的感觉"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTirmUJ7COBA",
        "outputId": "ac451498-0ac1-4876-a99d-66f0e020ccc1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2030, 1191, 3354,  987, 3748,  256, 2650,  828, 2914, 3517,  702, 2666,\n",
            "         3247, 2473, 3516, 2824],\n",
            "        [3755, 1143, 2170, 1840, 3005, 1639, 1853, 2184, 3026,  149, 2665, 1055,\n",
            "          406, 3474, 1240, 2015],\n",
            "        [1387,   62, 1356, 2730, 3000, 1471,  554,  399, 3320, 3449, 3220, 2496,\n",
            "           26, 2576, 1801, 2093],\n",
            "        [2203, 2671, 2455, 1684,  718, 3288, 2779, 3680, 1265, 2196,  578,   27,\n",
            "         1589, 1527,   64,  299],\n",
            "        [  10, 2507,  966, 1497, 1635,  648, 1586, 2647,  718, 3235, 1241, 3553,\n",
            "         2156, 1846, 2309, 1776],\n",
            "        [3312, 2619, 3611, 3591, 1380, 1427, 1549, 2403, 1998, 2006, 1904,  551,\n",
            "         3506, 3179, 3065, 1833],\n",
            "        [2455, 3247, 2880, 2834, 1317, 2563,  130, 1604,    6, 3296,  405, 3257,\n",
            "         3079, 3372,  980, 2699],\n",
            "        [ 677,  196, 2449, 2717, 2366, 3295,  905, 1281, 1359, 1644,  210, 1647,\n",
            "         3082,  317,   77, 3013]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = embd(token_ids)\n",
        "\n",
        "print(x.shape)\n",
        "\n",
        "# 这次感觉对了"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfEx9JEuCxOh",
        "outputId": "48118ac3-1f2d-4b69-f88c-5015a7e00405"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 16, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x\n",
        "# 观察了一下，这个值还是有点技巧的，大部分都在 += 1.0 左右"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvMJP-eQC9dQ",
        "outputId": "62d025b3-6cf6-4189-9eef-177f1b8733fc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.0483e+00, -3.7320e-01,  9.5842e-01,  ..., -6.3092e-01,\n",
              "          -5.0265e-01,  7.7691e-01],\n",
              "         [-1.2889e+00, -7.0146e-01,  1.9759e+00,  ...,  6.2977e-01,\n",
              "          -1.8848e+00, -1.9642e-01],\n",
              "         [-4.2325e-01, -9.0744e-01,  1.3034e+00,  ..., -1.1252e+00,\n",
              "          -2.8621e-01,  1.1301e-01],\n",
              "         ...,\n",
              "         [ 1.5173e+00,  1.4634e+00, -8.7972e-01,  ..., -2.6073e-02,\n",
              "           3.1359e-01, -1.2791e+00],\n",
              "         [-1.0178e+00, -5.6138e-01, -8.7657e-01,  ...,  8.1380e-01,\n",
              "           1.5480e-01, -3.5459e-01],\n",
              "         [ 4.3281e-01,  4.3787e-01,  3.1485e-01,  ...,  6.9691e-02,\n",
              "          -7.6486e-01, -3.8529e-01]],\n",
              "\n",
              "        [[ 1.3056e+00, -2.4012e-01, -1.9810e-01,  ...,  5.0410e-01,\n",
              "           4.5134e-01, -9.9609e-01],\n",
              "         [-2.6841e-02,  6.1632e-01, -2.0286e+00,  ...,  6.1581e-01,\n",
              "          -6.1157e-02, -1.0268e+00],\n",
              "         [-2.0581e-01,  2.2139e+00, -3.2843e-01,  ..., -5.8461e-01,\n",
              "           1.0483e-02,  1.5929e+00],\n",
              "         ...,\n",
              "         [-4.8183e-01, -5.1854e-01, -1.1807e+00,  ...,  2.7439e-01,\n",
              "           1.1940e+00,  2.9877e-01],\n",
              "         [-8.9279e-01, -1.3795e-01, -2.2144e+00,  ...,  3.8344e-01,\n",
              "           1.3014e-01,  2.6927e-01],\n",
              "         [ 1.1391e+00,  1.1309e-01, -2.4163e+00,  ..., -3.2295e-04,\n",
              "          -7.0174e-01,  7.2399e-02]],\n",
              "\n",
              "        [[-1.2956e-01,  5.0731e-01, -1.2034e+00,  ...,  1.9560e-01,\n",
              "           1.3025e-02,  1.1671e+00],\n",
              "         [ 3.0870e-01,  1.1183e+00,  3.1580e-01,  ..., -6.5085e-01,\n",
              "          -2.9972e-01,  8.4865e-01],\n",
              "         [ 1.2710e+00, -1.9662e-02, -9.4417e-01,  ...,  1.1169e+00,\n",
              "           2.7301e-01, -1.5655e+00],\n",
              "         ...,\n",
              "         [-4.0695e-01,  4.2478e-03, -2.2594e-01,  ..., -1.4194e-01,\n",
              "           1.6943e+00,  4.1593e-01],\n",
              "         [-1.1187e+00,  3.5829e-01,  2.3936e-01,  ...,  6.8531e-01,\n",
              "           1.5426e+00,  3.2978e-01],\n",
              "         [ 9.7455e-02, -1.0541e+00, -2.1294e-01,  ..., -7.9773e-01,\n",
              "           1.1956e+00, -5.0976e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-4.5485e-01, -1.2052e+00,  1.2119e+00,  ...,  2.8762e-01,\n",
              "          -1.1918e+00, -1.0739e+00],\n",
              "         [-1.4749e+00, -1.0324e+00,  1.6202e+00,  ..., -1.5348e-01,\n",
              "          -1.9626e+00, -1.9494e+00],\n",
              "         [-1.1463e+00,  9.9396e-02, -1.3964e-01,  ...,  4.1505e-01,\n",
              "           3.8202e-01,  2.5188e-01],\n",
              "         ...,\n",
              "         [-6.8313e-02,  7.8724e-01, -1.4870e+00,  ..., -8.0001e-01,\n",
              "          -7.1257e-01, -3.3399e-01],\n",
              "         [ 6.2144e-02, -1.2293e+00,  7.2068e-03,  ..., -3.0151e-01,\n",
              "           2.1230e-01,  4.4505e-01],\n",
              "         [-1.0336e+00, -1.6634e-01, -8.2131e-01,  ..., -9.1215e-02,\n",
              "          -3.9896e-01,  6.3822e-01]],\n",
              "\n",
              "        [[-8.5413e-01, -6.1741e-01, -1.6031e+00,  ...,  6.6553e-02,\n",
              "          -8.6651e-01,  5.1671e-01],\n",
              "         [ 7.0179e-02,  7.7383e-01, -4.2539e-01,  ..., -6.8923e-01,\n",
              "          -8.6820e-01, -1.4482e-01],\n",
              "         [ 1.2859e+00, -1.0920e+00, -8.1789e-01,  ...,  9.5892e-02,\n",
              "          -2.3779e+00,  6.1892e-01],\n",
              "         ...,\n",
              "         [ 3.7403e-01,  3.5655e-01, -2.5966e-01,  ..., -1.3689e-01,\n",
              "           9.8730e-01,  7.7668e-01],\n",
              "         [ 1.7516e+00, -9.0501e-01, -1.2657e+00,  ..., -4.0184e-01,\n",
              "           1.5503e+00,  8.1124e-01],\n",
              "         [-8.4322e-01, -1.1083e+00,  1.7734e+00,  ...,  1.3408e+00,\n",
              "           9.5400e-01,  3.4646e-01]],\n",
              "\n",
              "        [[-2.6227e+00, -1.0599e+00, -9.1388e-01,  ..., -2.6711e-02,\n",
              "          -4.0616e-01, -2.3474e-02],\n",
              "         [-9.1979e-01, -6.0343e-02,  1.6931e+00,  ..., -8.3210e-01,\n",
              "           4.8529e-01,  7.4314e-01],\n",
              "         [-9.9502e-01,  6.3299e-01, -3.4482e-01,  ..., -1.0148e+00,\n",
              "          -6.7021e-02,  1.6326e+00],\n",
              "         ...,\n",
              "         [ 5.8436e-01,  7.8343e-01,  9.4853e-01,  ..., -1.3521e+00,\n",
              "          -1.0882e+00,  5.2313e-01],\n",
              "         [ 8.6775e-01, -9.1390e-01, -1.1559e+00,  ..., -2.9894e-01,\n",
              "          -7.9826e-02, -1.3070e+00],\n",
              "         [-2.2773e-01, -5.7474e-02, -1.0775e+00,  ...,  8.8587e-01,\n",
              "           1.1242e+00, -7.3396e-01]]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# play attention\n",
        "关键词：**QKV** , **wei matrix**, **tril**, **softmax**\n",
        "\n",
        "对matrix的理解还有不够深刻，需要组织一段语言或者一个动图"
      ],
      "metadata": {
        "id": "VpuJUAqazPS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "headers_num = 8\n",
        "header_dim = embd_dim // headers_num\n",
        "\n",
        "query = nn.Linear(embd_dim, header_dim)\n",
        "key = nn.Linear(embd_dim, header_dim)\n",
        "value = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "q = query(x) # shape(B, T, header_dim) = (8, 16, 32)\n",
        "k = key(x)\n",
        "v = value(x)\n",
        "\n",
        "print(q.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsNUOtk-zSMF",
        "outputId": "5344ed52-3d8d-4254-8ef6-ce297567eb14"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 16, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "wei = q @ k.transpose(-2, -1)\n",
        "print(wei.shape) # shape(B, T, T)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "print(tril == 0)\n",
        "\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "\n",
        "# print(wei)\n",
        "\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "print(wei)\n",
        "\n",
        "x_attn = wei @ v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p193xjxY3dfR",
        "outputId": "1f4b9dea-533d-4954-bf3d-01d9ddd3135b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 16, 16])\n",
            "tensor([[False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False,  True,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False,  True,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False,  True,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False,  True,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False,  True,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False,  True,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False,  True,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "          True,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False,  True,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False,  True,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False,  True,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False,  True,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False,  True],\n",
            "        [False, False, False, False, False, False, False, False, False, False,\n",
            "         False, False, False, False, False, False]])\n",
            "tensor([[[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [7.5246e-02, 9.2475e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [1.8720e-02, 9.7026e-01, 1.1024e-02,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         ...,\n",
            "         [1.4967e-02, 4.6437e-02, 3.7875e-03,  ..., 2.0483e-04,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [1.7056e-02, 4.5133e-03, 6.6590e-03,  ..., 2.8632e-02,\n",
            "          1.2563e-01, 0.0000e+00],\n",
            "         [6.5041e-02, 3.2645e-02, 8.8252e-03,  ..., 1.0359e-03,\n",
            "          1.8731e-02, 3.9281e-03]],\n",
            "\n",
            "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [5.8072e-04, 9.9942e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [2.9739e-01, 4.1931e-01, 2.8330e-01,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         ...,\n",
            "         [6.3231e-02, 1.0559e-01, 2.0671e-01,  ..., 5.7907e-02,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [1.3779e-02, 2.7647e-01, 2.6493e-02,  ..., 1.1905e-02,\n",
            "          1.5479e-01, 0.0000e+00],\n",
            "         [1.0339e-01, 5.2946e-02, 6.0987e-03,  ..., 1.5283e-01,\n",
            "          1.0583e-01, 2.9475e-03]],\n",
            "\n",
            "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [5.6031e-01, 4.3969e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [2.6075e-01, 7.1577e-01, 2.3480e-02,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         ...,\n",
            "         [7.7053e-02, 1.3125e-02, 1.2596e-01,  ..., 3.9952e-02,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [3.8558e-02, 6.7377e-03, 1.1047e-01,  ..., 3.9970e-02,\n",
            "          1.2497e-02, 0.0000e+00],\n",
            "         [2.3026e-03, 2.7279e-02, 2.1823e-01,  ..., 2.9562e-01,\n",
            "          7.4099e-04, 5.1861e-03]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [9.1039e-01, 8.9613e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [2.3609e-01, 9.6897e-02, 6.6701e-01,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         ...,\n",
            "         [1.0717e-02, 2.5470e-02, 6.7821e-02,  ..., 6.1459e-01,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [2.0927e-03, 7.7209e-04, 7.9827e-01,  ..., 5.6017e-03,\n",
            "          2.7700e-03, 0.0000e+00],\n",
            "         [1.2807e-01, 5.5840e-03, 1.1914e-01,  ..., 1.5011e-01,\n",
            "          7.2552e-04, 4.0503e-02]],\n",
            "\n",
            "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [2.1271e-01, 7.8729e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [4.6127e-01, 4.9740e-01, 4.1331e-02,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         ...,\n",
            "         [4.4621e-01, 2.5388e-02, 3.5055e-02,  ..., 1.3296e-02,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [1.9160e-02, 1.8344e-02, 5.1646e-02,  ..., 3.1151e-01,\n",
            "          2.0085e-02, 0.0000e+00],\n",
            "         [4.0762e-03, 6.7331e-02, 2.0386e-02,  ..., 1.6012e-01,\n",
            "          6.0791e-02, 5.7139e-03]],\n",
            "\n",
            "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [8.5576e-01, 1.4424e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [1.4253e-01, 7.8435e-01, 7.3129e-02,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         ...,\n",
            "         [1.9136e-02, 1.8320e-01, 7.2769e-02,  ..., 1.7304e-02,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [6.2285e-02, 5.1728e-02, 4.8140e-02,  ..., 6.3833e-03,\n",
            "          9.0173e-03, 0.0000e+00],\n",
            "         [5.7991e-02, 1.9795e-02, 2.4225e-01,  ..., 3.5284e-05,\n",
            "          1.0790e-03, 3.7257e-03]]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# play MHA\n",
        "- 思路1: 肉写,比较机械 key1,query1,value1, key2,query2,value2...\n",
        "- 思路2: flatten一下，key_0to7。nn.Linear(embd_dim, header_dim * 8)\n",
        "- 思路3: nn.ModuleList(),印象中Andrej是用的这个，但是具体怎么用还没想好\n",
        "- 思路4: 之前问ChatGPT的实现，应该比较高效，是把多头的参数直接cat起来的"
      ],
      "metadata": {
        "id": "gEkK-url61bU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 思路1\n",
        "query1 = nn.Linear(embd_dim, header_dim)\n",
        "key1 = nn.Linear(embd_dim, header_dim)\n",
        "value1 = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "query2 = nn.Linear(embd_dim, header_dim)\n",
        "key2 = nn.Linear(embd_dim, header_dim)\n",
        "value2 = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "query3 = nn.Linear(embd_dim, header_dim)\n",
        "key3 = nn.Linear(embd_dim, header_dim)\n",
        "value3 = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "query4 = nn.Linear(embd_dim, header_dim)\n",
        "key4 = nn.Linear(embd_dim, header_dim)\n",
        "value4 = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "query5 = nn.Linear(embd_dim, header_dim)\n",
        "key5 = nn.Linear(embd_dim, header_dim)\n",
        "value5 = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "query6 = nn.Linear(embd_dim, header_dim)\n",
        "key6 = nn.Linear(embd_dim, header_dim)\n",
        "value6 = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "query7 = nn.Linear(embd_dim, header_dim)\n",
        "key7 = nn.Linear(embd_dim, header_dim)\n",
        "value7 = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "query8 = nn.Linear(embd_dim, header_dim)\n",
        "key8 = nn.Linear(embd_dim, header_dim)\n",
        "value8 = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "q1 = query1(x)\n",
        "k1 = key1(x)\n",
        "v1 = value1(x)\n",
        "\n",
        "q2 = query2(x)\n",
        "k2 = key2(x)\n",
        "v2 = value2(x)\n",
        "\n",
        "q3 = query3(x)\n",
        "k3 = key3(x)\n",
        "v3 = value3(x)\n",
        "\n",
        "q4 = query4(x)\n",
        "k4 = key4(x)\n",
        "v4 = value4(x)\n",
        "\n",
        "q5 = query5(x)\n",
        "k5 = key5(x)\n",
        "v5 = value5(x)\n",
        "\n",
        "q6 = query6(x)\n",
        "k6 = key6(x)\n",
        "v6 = value6(x)\n",
        "\n",
        "q7 = query7(x)\n",
        "k7 = key7(x)\n",
        "v7 = value7(x)\n",
        "\n",
        "q8 = query8(x)\n",
        "k8 = key8(x)\n",
        "v8 = value8(x)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "\n",
        "wei1 = q1 @ k1.transpose(-2, -1)\n",
        "wei1 = wei1.masked_fill(tril == 0, float('-inf'))\n",
        "wei1 = F.softmax(wei1, dim=-1)\n",
        "x_header_1 = wei1 @ v1\n",
        "\n",
        "wei2 = q2 @ k2.transpose(-2, -1)\n",
        "wei2 = wei2.masked_fill(tril == 0, float('-inf'))\n",
        "wei2 = F.softmax(wei2, dim=-1)\n",
        "x_header_2 = wei2 @ v2\n",
        "\n",
        "wei3 = q3 @ k3.transpose(-2, -1)\n",
        "wei3 = wei3.masked_fill(tril == 0, float('-inf'))\n",
        "wei3 = F.softmax(wei3, dim=-1)\n",
        "x_header_3 = wei3 @ v3\n",
        "\n",
        "wei4 = q4 @ k4.transpose(-2, -1)\n",
        "wei4 = wei4.masked_fill(tril == 0, float('-inf'))\n",
        "wei4 = F.softmax(wei4, dim=-1)\n",
        "x_header_4 = wei4 @ v4\n",
        "\n",
        "wei5 = q5 @ k5.transpose(-2, -1)\n",
        "wei5 = wei5.masked_fill(tril == 0, float('-inf'))\n",
        "wei5 = F.softmax(wei5, dim=-1)\n",
        "x_header_5 = wei5 @ v5\n",
        "\n",
        "wei6 = q6 @ k6.transpose(-2, -1)\n",
        "wei6 = wei6.masked_fill(tril == 0, float('-inf'))\n",
        "wei6 = F.softmax(wei6, dim=-1)\n",
        "x_header_6 = wei6 @ v6\n",
        "\n",
        "wei7 = q7 @ k7.transpose(-2, -1)\n",
        "wei7 = wei7.masked_fill(tril == 0, float('-inf'))\n",
        "wei7 = F.softmax(wei7, dim=-1)\n",
        "x_header_7 = wei7 @ v7\n",
        "\n",
        "wei8 = q8 @ k8.transpose(-2, -1)\n",
        "wei8 = wei2.masked_fill(tril == 0, float('-inf'))\n",
        "wei8 = F.softmax(wei8, dim=-1)\n",
        "x_header_8 = wei8 @ v8 # shape(B, T, header_dim)\n",
        "\n",
        "# 最后怎么合成到embd_dim，继续过FFN?\n",
        "# shape(B, T, header_dim)，可以不考虑前面B, T 然后想象8个attn concat起来，过一个FC\n",
        "# 这个等价于8个attn单独过一个自己的FC，然后再elementwise的add\n",
        "# 所以继续发扬暴力写法。。。\n",
        "\n",
        "fc1 = nn.Linear(header_dim, embd_dim)\n",
        "fc2 = nn.Linear(header_dim, embd_dim)\n",
        "fc3 = nn.Linear(header_dim, embd_dim)\n",
        "fc4 = nn.Linear(header_dim, embd_dim)\n",
        "fc5 = nn.Linear(header_dim, embd_dim)\n",
        "fc6 = nn.Linear(header_dim, embd_dim)\n",
        "fc7 = nn.Linear(header_dim, embd_dim)\n",
        "fc8 = nn.Linear(header_dim, embd_dim)\n",
        "\n",
        "x_mht = fc1(x_header_1) + fc2(x_header_2) + fc3(x_header_3) + fc4(x_header_4) + fc5(x_header_5) + fc6(x_header_6) + fc7(x_header_7) + fc8(x_header_8)\n",
        "\n",
        "print(x_mht.shape) # shape=(8, 16, 256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYS2IGbt65MD",
        "outputId": "26fcc2ad-b4ef-4f10-d506-fba2c31d1321"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 16, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ChatGPT提到当模型结构较为复杂，需要灵活地管理子模块而不是简单地按顺序执行时，nn.ModuleList 提供了更大的灵活性。"
      ],
      "metadata": {
        "id": "iS-x7qLpU2Ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 思路3，自己从头写\n",
        "\n",
        "query_list = nn.ModuleList([nn.Linear(embd_dim, header_dim)] * 8)\n",
        "key_list = nn.ModuleList([nn.Linear(embd_dim, header_dim)] * 8)\n",
        "value_list = nn.ModuleList([nn.Linear(embd_dim, header_dim)] * 8)\n",
        "\n",
        "q_list = [query(x) for query in query_list]\n",
        "k_list = [key(x) for key in key_list]\n",
        "v_list = [value(x) for value in value_list]\n",
        "\n",
        "x_header_list = list()\n",
        "for n in range(8):\n",
        "    wei = q_list[n] @ k_list[n].transpose(-2, -1)\n",
        "    wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "    wei = F.softmax(wei, dim=-1)\n",
        "    x_header = wei @ v[n]\n",
        "    x_header_list.append(x_header)\n",
        "\n",
        "fc_list = nn.ModuleList([nn.Linear(header_dim, embd_dim)] * 8)\n",
        "\n",
        "x_mht = torch.zeros(8, 16, embd_dim)\n",
        "for n in range(8):\n",
        "    fc = fc_list[n]\n",
        "    x_mht += fc(x_header_list[n])\n",
        "\n",
        "print(x_mht.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_bnFjsFUcFc",
        "outputId": "09ed1145-d8e4-474c-cf85-49aa20c77c6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 16, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 上面这种写法，感觉并行度不够，多头都是串行的。看看标准答案吧，哈哈。\n",
        "* 标准答案思路：Header和MultiHeader 2个类，然后ModuleList 进来，循环过完再cat+proj\n",
        "* 标准答案其实也有串行的部分！另外标准答案里面还有个dropout，这块之前没注意到\n",
        "* 另外还有一个，忘了除以根号d, 原因上节课有讲，是为了保证vars在1.0左右，不至于让softmax太peak变成了hardmax哈哈"
      ],
      "metadata": {
        "id": "6TZlM25qukUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 思路3，扫了下标准答案后\n",
        "class Header(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(embd_dim, header_dim)\n",
        "        self.key = nn.Linear(embd_dim, header_dim)\n",
        "        self.value = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        q = self.query(x)\n",
        "        k = self.key(x)\n",
        "        v = self.value(x)\n",
        "\n",
        "        wei = q @ k.transpose(-2, -1)\n",
        "\n",
        "        # 标准答案\n",
        "        # wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
        "\n",
        "        tril = torch.tril(torch.ones(T, T))\n",
        "        wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "        # 标准答案\n",
        "        # wei = self.dropout(wei)\n",
        "\n",
        "        x_attn = wei @ v\n",
        "\n",
        "        return x_attn\n",
        "\n",
        "class MultiHead(nn.ModuleList):\n",
        "    def __init__(self, headers_num=8):\n",
        "        super().__init__()\n",
        "\n",
        "        self.headers = nn.ModuleList([Header()] * headers_num)\n",
        "        self.proj = nn.Linear(header_dim * headers_num, embd_dim)\n",
        "        # 标准答案\n",
        "        # self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_header_list = [h(x) for h in self.headers] # shape (n, B, T, header_dim)\n",
        "        x_headers_flatten = torch.cat(x_header_list, dim=-1)\n",
        "        x_mha = self.proj(x_headers_flatten)\n",
        "\n",
        "        return x_mha\n",
        "\n",
        "\n",
        "multihead = MultiHead()\n",
        "x_mha = multihead(x)\n",
        "\n",
        "print(x_mha.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZSjckzxqU5f",
        "outputId": "9f5b7fa4-3229-4049-b490-8729dc3dda4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 16, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用在gpt-mao的代码，对比一下标准答案，有如下分析：\n",
        "1. **参数名更标准：** 标准答案参数名叫c_attn，这个是为了和Transformers库保持一致方便load模型\n",
        "2. **更高效：** 标准答案使用了nn.Linear(config.n_embd, 3 * config.n_embd)，一次搞定qkv。\n",
        "3. **遵循原论文：** shape从(B, T, C) -> (B, T, n_head, C // n_head) 保证了 C = n_head * head_size。 Think: 为啥要保证这个？\n",
        "4. **核心逻辑一致：**  (B, T, n_head, head_size) -> (B, n_head, T, head_size)。Think: 为什么这么处理还是没特别想透"
      ],
      "metadata": {
        "id": "SnXBBH2vV4WQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 思路4:\n",
        "\n",
        "class GPTConfig:\n",
        "    def __init__(self, config):\n",
        "        self.B = config['B']\n",
        "        self.T = config['T']\n",
        "        self.C = config['C']\n",
        "\n",
        "        self.vocab_size = config['vocab_size']\n",
        "\n",
        "        self.header_size = config['header_size']\n",
        "        self.headers_num = config['headers_num']\n",
        "\n",
        "        self.blocks_num = config['blocks_num']\n",
        "        self.ffn_size = config['ffn_size']\n",
        "\n",
        "class MultiHeadV4(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.key = nn.Linear(config.C, config.header_size * config.headers_num)\n",
        "        self.query = nn.Linear(config.C, config.header_size * config.headers_num)\n",
        "        self.value = nn.Linear(config.C, config.header_size * config.headers_num)\n",
        "        self.attn_fc = nn.Linear(config.header_size * config.headers_num, config.C)\n",
        "\n",
        "\n",
        "    def split_headers(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into (num_heads, head_dim) and transpose the result.\"\"\"\n",
        "        x = x.view(batch_size, config.T, self.config.headers_num, self.config.header_size)\n",
        "\n",
        "        return x.transpose(1, 2) # shape (B, headers_num, T, header_size) 这里需要thinking一下why\n",
        "\n",
        "    def combine_headers(self, x, batch_size):\n",
        "        \"\"\"\n",
        "            Combine the heads and restore the original last dimension.\n",
        "            x.shape (B, headers_num, T, header_size)\n",
        "        \"\"\"\n",
        "        x = x.transpose(1, 2).contiguous()\n",
        "        # 这里view中的-1，表示自动计算。其实可以直接用T\n",
        "        return x.view(batch_size, self.config.T, self.config.headers_num * self.config.header_size)\n",
        "\n",
        "    def attn(self, x):\n",
        "        \"\"\"\n",
        "        x.shape (B, T, C)\n",
        "        \"\"\"\n",
        "        config = self.config\n",
        "        B, T, C = x.shape\n",
        "\n",
        "        # k, q, v shape (B, headers_num, T, header_size)\n",
        "        k = self.split_headers(self.key(x), B)\n",
        "        q = self.split_headers(self.query(x), B)\n",
        "        v = self.split_headers(self.value(x), B)\n",
        "\n",
        "        tril = torch.tril(torch.ones(config.T, config.T))\n",
        "        wei = q @ k.transpose(-2, -1) # 这个时候用负数的兼容性就体现了\n",
        "        wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "        wei = wei / (config.header_size ** 0.5)\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        # wei.shape (B, headers_num, T, T)\n",
        "\n",
        "        out = wei @ v # out.shape (B, headers_num, T, header_size)\n",
        "        out = self.combine_headers(out, B)  # out.shape(B, T, config.header_size * config.headers_num)\n",
        "        x = self.attn_fc(out)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.attn(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "config = GPTConfig({'B': B, 'T': T, 'C': embd_dim, 'vocab_size': vocab_size, 'header_size': header_dim, 'headers_num': headers_num, 'blocks_num': 4, 'ffn_size': 256})\n",
        "mha = MultiHeadV4(config)\n",
        "\n",
        "x_mha_v4 = mha(x)\n",
        "print(x_mha_v4.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr1XiwHtQFdO",
        "outputId": "cb9a538c-724f-467b-ecbd-3592a119e86e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 16, 256])\n"
          ]
        }
      ]
    }
  ]
}