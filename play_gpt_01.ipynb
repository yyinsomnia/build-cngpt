{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "hQNXuf1bv-q8"
      ],
      "authorship_tag": "ABX9TyMlKiLfS2XrUa9iRjUqB6Op",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yyinsomnia/build-cngpt/blob/main/play_gpt_01.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# init 环境和数据\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hQNXuf1bv-q8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Iih4-H2Qvq07"
      },
      "outputs": [],
      "source": [
        "# ! pip install transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# play embd\n",
        "\n",
        "1. 首先还是要能learn的，不然就只有forward没有backward了"
      ],
      "metadata": {
        "id": "UiiUQAVswTAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# 模拟一个batch的input\n",
        "vocab_size = 3758  # 3500个常用字 + 256个ASCII + 2个[UNK] [MASK]\n",
        "B, T = 8, 16\n",
        "\n",
        "shape = (8, 16, 1) # (B, T, id)\n",
        "token_ids = torch.randint(low=0, high=3758, size=shape)\n",
        "print(token_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZw4qsuewRiH",
        "outputId": "569478c6-12f8-4ddd-832a-1cd461d37318"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[ 951],\n",
            "         [2189],\n",
            "         [2155],\n",
            "         [ 105],\n",
            "         [ 447],\n",
            "         [3740],\n",
            "         [2683],\n",
            "         [2492],\n",
            "         [2708],\n",
            "         [3524],\n",
            "         [2501],\n",
            "         [1120],\n",
            "         [1576],\n",
            "         [ 725],\n",
            "         [ 875],\n",
            "         [2654]],\n",
            "\n",
            "        [[ 181],\n",
            "         [3262],\n",
            "         [ 888],\n",
            "         [2741],\n",
            "         [2820],\n",
            "         [ 608],\n",
            "         [2665],\n",
            "         [ 732],\n",
            "         [2132],\n",
            "         [1529],\n",
            "         [ 705],\n",
            "         [3753],\n",
            "         [ 512],\n",
            "         [3737],\n",
            "         [2071],\n",
            "         [2309]],\n",
            "\n",
            "        [[2918],\n",
            "         [1098],\n",
            "         [2776],\n",
            "         [3629],\n",
            "         [3266],\n",
            "         [1204],\n",
            "         [1654],\n",
            "         [2193],\n",
            "         [2455],\n",
            "         [ 154],\n",
            "         [3024],\n",
            "         [1629],\n",
            "         [1227],\n",
            "         [1984],\n",
            "         [3713],\n",
            "         [2866]],\n",
            "\n",
            "        [[2097],\n",
            "         [1435],\n",
            "         [ 462],\n",
            "         [2670],\n",
            "         [ 188],\n",
            "         [ 897],\n",
            "         [ 796],\n",
            "         [3326],\n",
            "         [3010],\n",
            "         [ 158],\n",
            "         [1806],\n",
            "         [1589],\n",
            "         [1745],\n",
            "         [3302],\n",
            "         [2540],\n",
            "         [3374]],\n",
            "\n",
            "        [[2800],\n",
            "         [2391],\n",
            "         [1163],\n",
            "         [ 275],\n",
            "         [1013],\n",
            "         [1981],\n",
            "         [2232],\n",
            "         [1984],\n",
            "         [1433],\n",
            "         [2039],\n",
            "         [2888],\n",
            "         [ 778],\n",
            "         [2374],\n",
            "         [3755],\n",
            "         [1821],\n",
            "         [2727]],\n",
            "\n",
            "        [[3491],\n",
            "         [2356],\n",
            "         [1710],\n",
            "         [3508],\n",
            "         [3209],\n",
            "         [1225],\n",
            "         [1649],\n",
            "         [ 745],\n",
            "         [1464],\n",
            "         [1747],\n",
            "         [2325],\n",
            "         [2088],\n",
            "         [2482],\n",
            "         [2114],\n",
            "         [ 417],\n",
            "         [1812]],\n",
            "\n",
            "        [[2542],\n",
            "         [ 897],\n",
            "         [2739],\n",
            "         [1170],\n",
            "         [2990],\n",
            "         [ 110],\n",
            "         [3257],\n",
            "         [ 388],\n",
            "         [ 302],\n",
            "         [1926],\n",
            "         [ 730],\n",
            "         [1242],\n",
            "         [1225],\n",
            "         [ 570],\n",
            "         [ 243],\n",
            "         [ 796]],\n",
            "\n",
            "        [[1774],\n",
            "         [2992],\n",
            "         [1256],\n",
            "         [2565],\n",
            "         [1427],\n",
            "         [2746],\n",
            "         [2773],\n",
            "         [1347],\n",
            "         [1645],\n",
            "         [3113],\n",
            "         [1003],\n",
            "         [1340],\n",
            "         [ 789],\n",
            "         [2267],\n",
            "         [3298],\n",
            "         [2979]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 注意：这里的共3个维度，最后一维度也是向量。"
      ],
      "metadata": {
        "id": "4ORnwBdQ2evA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 第2个batch的第4个token，也是一个向量\n",
        "print(token_ids[1, 3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exYxWoqI2MIK",
        "outputId": "9d6bb30c-4c51-441f-bedd-f1e0fbaeeb1c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2741])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "\n",
        "embd_dim = 256\n",
        "\n",
        "embd = nn.Embedding(vocab_size, embd_dim)\n",
        "\n",
        "x = embd(token_ids)\n",
        "\n",
        "print(x.shape) # (B, T, C) C就是embd_dim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdBrIiwU36Uf",
        "outputId": "10411d38-3eb9-4365-d750-d33453155b35"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 16, 1, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "发现shape和预期的不符合\n",
        "\n",
        "pytorch的docs里面\n",
        "Shape Input: (\\*) Output: (\\*, H)\n"
      ],
      "metadata": {
        "id": "Hk_NyIa3-dAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRXWKEiC5y1I",
        "outputId": "a9e06774-9ea8-4409-aa6c-9baedde377f4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 7.9044e-01, -4.6274e-01, -6.6431e-01,  ..., -7.5047e-01,\n",
              "            1.1894e+00, -1.1299e+00]],\n",
              "\n",
              "         [[ 6.7120e-01, -6.4540e-01, -1.5818e-01,  ..., -4.1572e-02,\n",
              "            5.4884e-01, -4.7011e-01]],\n",
              "\n",
              "         [[ 8.8286e-01, -2.4676e-01, -5.8604e-01,  ...,  2.7456e-01,\n",
              "           -4.9549e-01,  1.7087e+00]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 3.7835e-01,  6.4716e-01,  1.0535e+00,  ..., -1.5698e-01,\n",
              "            2.5416e-02, -6.5913e-01]],\n",
              "\n",
              "         [[-5.6564e-01,  6.6039e-02, -2.6857e-01,  ...,  7.3935e-01,\n",
              "            5.1131e-01, -1.9955e-01]],\n",
              "\n",
              "         [[ 1.7279e-01, -1.6990e+00,  2.4947e+00,  ...,  2.1290e-01,\n",
              "           -8.6340e-02, -8.0215e-01]]],\n",
              "\n",
              "\n",
              "        [[[ 1.5225e+00,  1.5168e+00,  6.8566e-01,  ..., -4.3976e-01,\n",
              "            9.6012e-01, -5.8410e-01]],\n",
              "\n",
              "         [[ 3.2221e-01, -9.1751e-01,  1.0769e+00,  ..., -4.3456e-01,\n",
              "            4.7245e-01,  8.6417e-01]],\n",
              "\n",
              "         [[ 2.6101e-01,  4.5095e-01, -7.1495e-01,  ...,  5.3278e-01,\n",
              "           -2.3575e-01,  8.5281e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-1.3802e+00, -1.3975e-01,  2.4182e-01,  ..., -1.6765e+00,\n",
              "            3.3951e-01, -1.5246e+00]],\n",
              "\n",
              "         [[-7.8558e-01,  1.8957e+00, -7.4713e-01,  ..., -6.2092e-01,\n",
              "           -1.8869e+00,  4.9219e-01]],\n",
              "\n",
              "         [[-4.0655e-01, -2.9015e-01,  4.1009e-01,  ...,  4.9893e-01,\n",
              "           -1.8273e-03,  7.1806e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.4434e-01, -8.3533e-01, -1.6770e-01,  ..., -4.7172e-02,\n",
              "            5.7362e-01,  2.1817e-01]],\n",
              "\n",
              "         [[ 1.5009e+00, -4.4419e-01,  1.7845e+00,  ..., -3.9291e-01,\n",
              "           -5.5158e-01,  1.1904e-01]],\n",
              "\n",
              "         [[ 8.7274e-02, -2.9226e-01, -9.9970e-01,  ...,  5.2988e-01,\n",
              "           -1.5134e+00, -2.5927e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[-1.6454e+00, -1.3524e+00,  1.3059e+00,  ...,  9.6896e-01,\n",
              "            1.9274e-01,  3.4465e-01]],\n",
              "\n",
              "         [[-3.3891e-01,  2.8739e-02,  7.2118e-02,  ...,  1.9494e+00,\n",
              "           -7.2805e-01, -1.2070e+00]],\n",
              "\n",
              "         [[-1.4990e-02, -1.4634e+00, -1.1559e+00,  ...,  5.3481e-02,\n",
              "            1.0042e+00,  1.4785e+00]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[ 7.2595e-01,  8.0409e-01, -1.0862e+00,  ..., -1.2968e+00,\n",
              "           -8.3674e-01,  5.6421e-01]],\n",
              "\n",
              "         [[ 1.4289e-01, -6.4901e-01,  1.4451e+00,  ..., -3.3421e-01,\n",
              "           -2.0380e+00,  4.3206e-01]],\n",
              "\n",
              "         [[-1.4608e+00, -3.2144e-02, -1.1009e+00,  ..., -1.0322e+00,\n",
              "            6.1637e-01,  1.3774e+00]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 3.2993e-01, -6.5230e-01,  8.8796e-01,  ...,  9.3864e-01,\n",
              "            4.8975e-01, -4.6545e-01]],\n",
              "\n",
              "         [[ 3.2577e+00, -2.4424e-01,  7.1570e-02,  ..., -9.0398e-01,\n",
              "           -6.2887e-01,  1.0950e-01]],\n",
              "\n",
              "         [[-1.7938e+00, -8.3712e-01,  9.3126e-01,  ..., -3.0767e-01,\n",
              "           -1.6918e+00, -2.7124e-02]]],\n",
              "\n",
              "\n",
              "        [[[-1.3925e+00,  3.7692e-02, -1.2564e+00,  ...,  9.1634e-02,\n",
              "           -3.8743e-01, -6.8898e-01]],\n",
              "\n",
              "         [[-2.9149e-01,  5.6010e-01,  8.2007e-01,  ...,  2.1604e-01,\n",
              "            1.4024e-02,  2.5657e-01]],\n",
              "\n",
              "         [[-2.0413e-01,  1.2975e+00, -2.0212e-01,  ...,  4.4107e-01,\n",
              "           -2.0872e+00, -5.5096e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 1.0033e+00, -6.6250e-01,  4.0292e-01,  ...,  1.8130e+00,\n",
              "            2.0290e-01, -3.1554e-01]],\n",
              "\n",
              "         [[ 2.5736e-01,  3.2881e-01, -1.2900e+00,  ...,  4.5421e-01,\n",
              "            9.1638e-01,  3.2731e-01]],\n",
              "\n",
              "         [[ 2.0588e+00,  4.6696e-01, -9.7039e-01,  ..., -4.9167e-02,\n",
              "            8.7866e-01,  6.4321e-01]]],\n",
              "\n",
              "\n",
              "        [[[-2.2302e-01,  4.3072e-01, -1.1394e+00,  ...,  5.0240e-01,\n",
              "           -6.4117e-01, -3.3546e-01]],\n",
              "\n",
              "         [[-6.6800e-01, -1.6026e+00,  9.4368e-01,  ..., -2.9807e-02,\n",
              "           -4.2319e-01, -1.2109e+00]],\n",
              "\n",
              "         [[ 5.9091e-01, -3.3348e-03,  6.4097e-01,  ...,  2.0240e+00,\n",
              "           -6.2718e-01,  9.2094e-01]],\n",
              "\n",
              "         ...,\n",
              "\n",
              "         [[ 9.3626e-01,  5.8257e-01,  1.5367e+00,  ..., -1.3232e+00,\n",
              "           -1.7949e+00,  2.7725e-01]],\n",
              "\n",
              "         [[ 6.8447e-01, -5.7329e-04,  1.3967e+00,  ..., -1.0623e+00,\n",
              "           -4.9326e-01,  1.8496e+00]],\n",
              "\n",
              "         [[-1.8572e+00,  2.9110e-01, -2.2069e+00,  ...,  4.2175e-01,\n",
              "           -4.0040e-01, -8.3320e-01]]]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "仔细想一下是合理的。如果是图片，那有RGB 3个值，就变成了(B, H, W, 3)\n",
        "这样RGB每个过完embd，应该是变成了(B, H, W, 3, embd_dim)"
      ],
      "metadata": {
        "id": "oATsRJZOAg2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 简单一点把最后一维弄成标量看看\n",
        "shape = (8, 16,)\n",
        "token_ids = torch.randint(low=0, high=vocab_size, size=shape)\n",
        "print(token_ids)\n",
        "# 这个输出是熟悉的感觉"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTirmUJ7COBA",
        "outputId": "a8227286-0ae5-4971-99c1-1ab9ce2c9a8a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2820, 2344, 2173, 1719,  560, 1713, 2056, 1003, 3373, 3288, 1994, 1692,\n",
            "         1785, 3689, 3426, 2652],\n",
            "        [ 369,  974, 1903, 1365, 1346,  761, 3086, 1609,  650,  748,  788, 3150,\n",
            "          875, 2635, 2943,  436],\n",
            "        [3326, 1979, 3693,  739, 2944, 2652, 2030, 1900, 2071,  231, 2280, 1980,\n",
            "         2682, 3041, 1047, 3103],\n",
            "        [2846, 2745, 1294, 3678,  165,  397, 1764, 1575, 1586, 2438,  571, 2705,\n",
            "         3175, 3184, 2128, 1847],\n",
            "        [2943, 1853, 1375, 1507, 1652, 1078, 3545, 2400, 3527, 3189, 2484, 2200,\n",
            "         1069,  620, 2052,  670],\n",
            "        [1720,  937,  700,  354, 3105,  742, 3178, 1433, 3352, 2261, 3116,   61,\n",
            "          702,  268,  982, 1666],\n",
            "        [1573, 1763, 3232,   26, 2098, 1401, 2488,  789, 2925,  980, 3655,  334,\n",
            "         1363,  821, 3592, 1311],\n",
            "        [ 913, 2662, 3564, 2456, 2317, 2730, 2772, 1221, 2439, 1836, 1254, 1778,\n",
            "         3112, 2447, 3209, 3121]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = embd(token_ids)\n",
        "\n",
        "print(x.shape)\n",
        "\n",
        "# 这次感觉对了"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfEx9JEuCxOh",
        "outputId": "bf259b15-5579-43cc-e22b-0408c1f1a624"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 16, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x\n",
        "# 观察了一下，这个值还是有点技巧的，大部分都在 +- 1.0 左右"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KvMJP-eQC9dQ",
        "outputId": "2200656c-2efc-403c-bb9b-f13023809cc5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.6951e+00, -2.9907e-01,  5.5990e-01,  ..., -2.1972e-02,\n",
              "           2.1995e-01,  9.7566e-01],\n",
              "         [-1.3859e+00,  1.1260e+00, -9.1951e-01,  ..., -2.7017e-01,\n",
              "          -3.6381e-01, -9.3985e-01],\n",
              "         [ 1.6992e+00,  9.3352e-01, -2.2224e+00,  ..., -9.2359e-01,\n",
              "          -1.7415e+00, -5.1062e-01],\n",
              "         ...,\n",
              "         [ 3.9704e-02,  3.0490e-02, -1.8918e-01,  ..., -7.6731e-02,\n",
              "           1.2411e+00,  1.0503e+00],\n",
              "         [ 6.5356e-01, -1.3521e-01,  1.3906e-01,  ..., -1.2789e+00,\n",
              "          -1.0857e+00,  8.2030e-02],\n",
              "         [-6.2034e-01,  8.1095e-01, -9.5309e-01,  ..., -1.2244e+00,\n",
              "          -6.7006e-04,  6.0653e-01]],\n",
              "\n",
              "        [[-2.2803e-01,  4.8385e-01, -1.3307e+00,  ..., -1.1325e-01,\n",
              "          -7.1718e-01,  6.0544e-01],\n",
              "         [ 5.7860e-01,  5.9058e-01, -8.3402e-01,  ..., -2.9735e-01,\n",
              "           1.9023e+00, -9.1666e-01],\n",
              "         [ 2.1054e+00, -1.1658e-01,  8.0937e-01,  ..., -3.7553e-01,\n",
              "           5.6007e-01, -1.6357e+00],\n",
              "         ...,\n",
              "         [ 7.3999e-01,  1.1982e+00,  5.3032e-01,  ..., -1.7219e+00,\n",
              "          -5.2208e-01, -2.2148e-01],\n",
              "         [ 2.1236e+00,  1.5654e+00,  9.0418e-01,  ...,  9.8077e-02,\n",
              "           4.4334e-01,  5.7350e-01],\n",
              "         [ 9.0212e-01,  1.5816e-01,  2.1545e+00,  ...,  1.7703e+00,\n",
              "           1.4485e+00, -1.2752e+00]],\n",
              "\n",
              "        [[-2.4308e+00, -4.8933e-01,  2.4610e-01,  ..., -9.4554e-01,\n",
              "          -9.6216e-01,  1.5205e-01],\n",
              "         [ 2.0717e+00, -1.3021e-02, -2.6039e+00,  ..., -1.6395e+00,\n",
              "           6.9597e-01, -1.7653e+00],\n",
              "         [ 1.0075e+00,  7.4807e-01,  4.7261e-01,  ..., -1.2731e+00,\n",
              "          -2.9346e-01, -4.2516e-01],\n",
              "         ...,\n",
              "         [ 1.4714e+00,  5.3407e-01,  6.8881e-01,  ...,  5.0037e-01,\n",
              "          -1.5077e-01, -6.2796e-01],\n",
              "         [-9.7567e-01,  1.3738e+00, -7.3551e-03,  ...,  9.9841e-01,\n",
              "           1.8313e+00, -6.7288e-01],\n",
              "         [ 4.4004e-02, -1.3044e+00,  1.1509e+00,  ..., -2.1175e+00,\n",
              "          -1.1053e+00, -7.3744e-01]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-8.0123e-01, -8.1732e-01,  1.3333e+00,  ..., -2.7798e+00,\n",
              "          -1.2739e+00, -3.7952e-02],\n",
              "         [-1.6267e+00,  3.1569e-02,  7.7311e-01,  ...,  2.4849e+00,\n",
              "           1.6368e+00, -1.2937e-01],\n",
              "         [-3.1289e+00,  1.8852e+00,  1.8193e-01,  ...,  1.6592e+00,\n",
              "          -1.4997e+00,  1.0634e+00],\n",
              "         ...,\n",
              "         [ 6.5637e-01, -4.3930e-01,  1.1824e-02,  ...,  6.4991e-01,\n",
              "           1.1901e+00,  6.6917e-01],\n",
              "         [-4.2785e-01,  1.3936e+00,  8.6849e-01,  ...,  4.1751e-01,\n",
              "          -1.1194e+00, -3.1026e-01],\n",
              "         [ 2.3886e-01, -2.7961e+00,  2.1440e-01,  ..., -3.0171e-02,\n",
              "          -1.5191e-01, -8.6778e-01]],\n",
              "\n",
              "        [[-8.1134e-01, -6.1263e-01,  1.1261e+00,  ..., -3.7002e-01,\n",
              "          -4.7276e-01,  1.1048e+00],\n",
              "         [-7.7794e-01,  5.9873e-01, -1.2384e-01,  ...,  1.1680e-01,\n",
              "           6.0504e-01,  3.7048e-01],\n",
              "         [-3.5050e-01, -2.3147e-01,  1.3877e+00,  ...,  1.6745e+00,\n",
              "          -1.3858e+00,  7.3243e-01],\n",
              "         ...,\n",
              "         [-2.0283e-01,  3.3251e-01, -2.2871e-01,  ..., -1.4393e-01,\n",
              "           7.9095e-01,  1.3794e-01],\n",
              "         [-1.1822e+00,  6.5295e-01,  2.2464e+00,  ...,  3.8369e-01,\n",
              "           7.0585e-01,  2.2678e-01],\n",
              "         [-3.1124e-02,  1.9031e+00,  1.6842e+00,  ...,  7.0504e-01,\n",
              "           6.3636e-01,  8.6498e-01]],\n",
              "\n",
              "        [[ 1.6052e+00,  2.3111e-01,  1.0117e-01,  ..., -1.1446e+00,\n",
              "          -1.8309e+00,  1.2242e-02],\n",
              "         [ 6.5653e-01, -1.2083e+00,  4.3187e-01,  ..., -2.0304e+00,\n",
              "          -1.1104e+00, -2.7542e-01],\n",
              "         [ 8.4214e-01,  1.6931e+00,  1.6108e+00,  ...,  8.3744e-01,\n",
              "          -7.9690e-01, -7.6725e-01],\n",
              "         ...,\n",
              "         [ 3.1170e-01,  1.4988e+00, -2.5311e+00,  ...,  2.5511e-01,\n",
              "          -6.3036e-01,  7.2419e-03],\n",
              "         [ 1.6920e-01,  5.9122e-01, -1.3946e+00,  ..., -7.0625e-01,\n",
              "          -5.0925e-02, -2.0264e+00],\n",
              "         [-4.3576e-01,  3.6535e-01,  1.2749e+00,  ..., -4.8496e-01,\n",
              "           2.9527e-01,  2.1262e+00]]], grad_fn=<EmbeddingBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# play attention\n",
        "关键词：**QKV** , **wei matrix**, **tril**, **softmax**\n",
        "\n",
        "对matrix的理解还有不够深刻，需要组织一段语言或者一个动图"
      ],
      "metadata": {
        "id": "VpuJUAqazPS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "headers_num = 8\n",
        "header_dim = embd_dim // headers_num\n",
        "\n",
        "query = nn.Linear(embd_dim, header_dim)\n",
        "key = nn.Linear(embd_dim, header_dim)\n",
        "value = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "q = query(x) # shape(B, T, header_dim) = (8, 16, 32)\n",
        "k = key(x)\n",
        "v = value(x)\n",
        "\n",
        "print(q.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OsNUOtk-zSMF",
        "outputId": "90cee0b6-8bff-47bb-b393-850a8f62c5f4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 16, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "wei = q @ k.transpose(-2, -1)\n",
        "print(wei.shape) # shape(B, T, T)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "print(tril)\n",
        "\n",
        "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "\n",
        "# print(wei)\n",
        "\n",
        "wei = F.softmax(wei, dim=-1)\n",
        "print(wei)\n",
        "\n",
        "x_attn = wei @ v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p193xjxY3dfR",
        "outputId": "8b07b26e-09b7-473e-bf08-5314412cc418"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 16, 16])\n",
            "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.],\n",
            "        [1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]])\n",
            "tensor([[[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [3.2474e-01, 6.7526e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [6.3906e-04, 9.4535e-01, 5.4006e-02,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         ...,\n",
            "         [5.8379e-03, 1.9255e-02, 2.1809e-03,  ..., 8.2497e-03,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [5.3273e-03, 1.0791e-04, 1.2199e-01,  ..., 5.9493e-04,\n",
            "          1.8817e-02, 0.0000e+00],\n",
            "         [4.9993e-02, 2.7810e-02, 9.8961e-02,  ..., 3.0299e-02,\n",
            "          2.7439e-02, 4.6818e-03]],\n",
            "\n",
            "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [8.8315e-02, 9.1168e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [7.0929e-01, 4.6456e-02, 2.4426e-01,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         ...,\n",
            "         [2.5369e-02, 8.5076e-02, 4.3973e-01,  ..., 3.0998e-03,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [6.6345e-03, 3.9061e-02, 5.0934e-04,  ..., 3.1106e-02,\n",
            "          1.2451e-02, 0.0000e+00],\n",
            "         [4.9539e-02, 3.0408e-02, 1.3622e-03,  ..., 4.4590e-03,\n",
            "          3.4701e-02, 4.7334e-03]],\n",
            "\n",
            "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [5.6735e-01, 4.3265e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [4.0339e-01, 5.3443e-01, 6.2181e-02,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         ...,\n",
            "         [3.9511e-03, 2.3575e-01, 2.2138e-02,  ..., 3.9695e-02,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [3.7356e-02, 2.4328e-03, 1.8795e-01,  ..., 1.2468e-01,\n",
            "          3.0936e-02, 0.0000e+00],\n",
            "         [3.5301e-01, 3.6493e-03, 4.5670e-02,  ..., 9.1920e-03,\n",
            "          2.9242e-02, 6.8703e-02]],\n",
            "\n",
            "        ...,\n",
            "\n",
            "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [8.3552e-01, 1.6448e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [8.7076e-01, 6.6605e-02, 6.2632e-02,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         ...,\n",
            "         [2.5682e-02, 5.6789e-03, 2.6041e-01,  ..., 3.0519e-02,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [5.1888e-03, 2.9294e-01, 1.4904e-01,  ..., 1.0895e-02,\n",
            "          9.1186e-03, 0.0000e+00],\n",
            "         [5.9461e-02, 5.0366e-01, 1.7054e-03,  ..., 5.5274e-03,\n",
            "          1.4365e-01, 5.8895e-03]],\n",
            "\n",
            "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [9.1957e-01, 8.0428e-02, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [1.2937e-02, 9.1377e-02, 8.9569e-01,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         ...,\n",
            "         [1.2741e-02, 2.7311e-01, 1.9895e-03,  ..., 3.0674e-01,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [1.7953e-02, 1.0518e-02, 1.3604e-01,  ..., 1.1134e-02,\n",
            "          7.2636e-02, 0.0000e+00],\n",
            "         [5.4215e-04, 4.2222e-02, 4.6779e-02,  ..., 2.1639e-03,\n",
            "          3.2590e-03, 7.0397e-03]],\n",
            "\n",
            "        [[1.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [7.6652e-01, 2.3348e-01, 0.0000e+00,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [9.9383e-01, 5.7245e-03, 4.4916e-04,  ..., 0.0000e+00,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         ...,\n",
            "         [1.6398e-02, 1.9261e-03, 3.7690e-03,  ..., 2.4301e-04,\n",
            "          0.0000e+00, 0.0000e+00],\n",
            "         [4.8050e-03, 6.9307e-03, 1.8333e-01,  ..., 2.7551e-01,\n",
            "          2.6140e-03, 0.0000e+00],\n",
            "         [7.5218e-04, 9.7484e-05, 1.4770e-04,  ..., 4.1891e-05,\n",
            "          1.3704e-05, 5.3072e-05]]], grad_fn=<SoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# play MHA\n",
        "- 思路1: 肉写,比较机械 key1,query1,value1, key2,query2,value2...\n",
        "- 思路2: flatten一下，key_0to7。nn.Linear(embd_dim, header_dim * 8)\n",
        "- 思路3: nn.ModuleList(),印象中Andrej是用的这个，但是具体怎么用还没想好\n",
        "- 思路4: 之前问ChatGPT的实现，应该比较高效，是把多头的参数直接cat起来的"
      ],
      "metadata": {
        "id": "gEkK-url61bU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 思路1\n",
        "query1 = nn.Linear(embd_dim, header_dim)\n",
        "key1 = nn.Linear(embd_dim, header_dim)\n",
        "value1 = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "query2 = nn.Linear(embd_dim, header_dim)\n",
        "key2 = nn.Linear(embd_dim, header_dim)\n",
        "value2 = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "query3 = nn.Linear(embd_dim, header_dim)\n",
        "key3 = nn.Linear(embd_dim, header_dim)\n",
        "value3 = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "query4 = nn.Linear(embd_dim, header_dim)\n",
        "key4 = nn.Linear(embd_dim, header_dim)\n",
        "value4 = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "query5 = nn.Linear(embd_dim, header_dim)\n",
        "key5 = nn.Linear(embd_dim, header_dim)\n",
        "value5 = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "query6 = nn.Linear(embd_dim, header_dim)\n",
        "key6 = nn.Linear(embd_dim, header_dim)\n",
        "value6 = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "query7 = nn.Linear(embd_dim, header_dim)\n",
        "key7 = nn.Linear(embd_dim, header_dim)\n",
        "value7 = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "query8 = nn.Linear(embd_dim, header_dim)\n",
        "key8 = nn.Linear(embd_dim, header_dim)\n",
        "value8 = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "q1 = query1(x)\n",
        "k1 = key1(x)\n",
        "v1 = value1(x)\n",
        "\n",
        "q2 = query2(x)\n",
        "k2 = key2(x)\n",
        "v2 = value2(x)\n",
        "\n",
        "q3 = query3(x)\n",
        "k3 = key3(x)\n",
        "v3 = value3(x)\n",
        "\n",
        "q4 = query4(x)\n",
        "k4 = key4(x)\n",
        "v4 = value4(x)\n",
        "\n",
        "q5 = query5(x)\n",
        "k5 = key5(x)\n",
        "v5 = value5(x)\n",
        "\n",
        "q6 = query6(x)\n",
        "k6 = key6(x)\n",
        "v6 = value6(x)\n",
        "\n",
        "q7 = query7(x)\n",
        "k7 = key7(x)\n",
        "v7 = value7(x)\n",
        "\n",
        "q8 = query8(x)\n",
        "k8 = key8(x)\n",
        "v8 = value8(x)\n",
        "\n",
        "tril = torch.tril(torch.ones(T, T))\n",
        "\n",
        "wei1 = q1 @ k1.transpose(-2, -1)\n",
        "wei1 = wei1.masked_fill(tril == 0, float('-inf'))\n",
        "wei1 = F.softmax(wei1, dim=-1)\n",
        "x_header_1 = wei1 @ v1\n",
        "\n",
        "wei2 = q2 @ k2.transpose(-2, -1)\n",
        "wei2 = wei2.masked_fill(tril == 0, float('-inf'))\n",
        "wei2 = F.softmax(wei2, dim=-1)\n",
        "x_header_2 = wei2 @ v2\n",
        "\n",
        "wei3 = q3 @ k3.transpose(-2, -1)\n",
        "wei3 = wei3.masked_fill(tril == 0, float('-inf'))\n",
        "wei3 = F.softmax(wei3, dim=-1)\n",
        "x_header_3 = wei3 @ v3\n",
        "\n",
        "wei4 = q4 @ k4.transpose(-2, -1)\n",
        "wei4 = wei4.masked_fill(tril == 0, float('-inf'))\n",
        "wei4 = F.softmax(wei4, dim=-1)\n",
        "x_header_4 = wei4 @ v4\n",
        "\n",
        "wei5 = q5 @ k5.transpose(-2, -1)\n",
        "wei5 = wei5.masked_fill(tril == 0, float('-inf'))\n",
        "wei5 = F.softmax(wei5, dim=-1)\n",
        "x_header_5 = wei5 @ v5\n",
        "\n",
        "wei6 = q6 @ k6.transpose(-2, -1)\n",
        "wei6 = wei6.masked_fill(tril == 0, float('-inf'))\n",
        "wei6 = F.softmax(wei6, dim=-1)\n",
        "x_header_6 = wei6 @ v6\n",
        "\n",
        "wei7 = q7 @ k7.transpose(-2, -1)\n",
        "wei7 = wei7.masked_fill(tril == 0, float('-inf'))\n",
        "wei7 = F.softmax(wei7, dim=-1)\n",
        "x_header_7 = wei7 @ v7\n",
        "\n",
        "wei8 = q8 @ k8.transpose(-2, -1)\n",
        "wei8 = wei2.masked_fill(tril == 0, float('-inf'))\n",
        "wei8 = F.softmax(wei8, dim=-1)\n",
        "x_header_8 = wei8 @ v8 # shape(B, T, header_dim)\n",
        "\n",
        "# 最后怎么合成到embd_dim，继续过FFN?\n",
        "# shape(B, T, header_dim)，可以不考虑前面B, T 然后想象8个attn concat起来，过一个FC\n",
        "# 这个等价于8个attn单独过一个自己的FC，然后再elementwise的add\n",
        "# 所以继续发扬暴力写法。。。\n",
        "\n",
        "fc1 = nn.Linear(header_dim, embd_dim)\n",
        "fc2 = nn.Linear(header_dim, embd_dim)\n",
        "fc3 = nn.Linear(header_dim, embd_dim)\n",
        "fc4 = nn.Linear(header_dim, embd_dim)\n",
        "fc5 = nn.Linear(header_dim, embd_dim)\n",
        "fc6 = nn.Linear(header_dim, embd_dim)\n",
        "fc7 = nn.Linear(header_dim, embd_dim)\n",
        "fc8 = nn.Linear(header_dim, embd_dim)\n",
        "\n",
        "x_mht = fc1(x_header_1) + fc2(x_header_2) + fc3(x_header_3) + fc4(x_header_4) + fc5(x_header_5) + fc6(x_header_6) + fc7(x_header_7) + fc8(x_header_8)\n",
        "\n",
        "print(x_mht.shape) # shape=(8, 16, 256)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYS2IGbt65MD",
        "outputId": "357b72dc-2e4e-41d6-b246-fae45e4d1f89"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 16, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* ChatGPT提到当模型结构较为复杂，需要灵活地管理子模块而不是简单地按顺序执行时，nn.ModuleList 提供了更大的灵活性。"
      ],
      "metadata": {
        "id": "iS-x7qLpU2Ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 思路3，自己从头写\n",
        "\n",
        "query_list = nn.ModuleList([nn.Linear(embd_dim, header_dim)] * 8)\n",
        "key_list = nn.ModuleList([nn.Linear(embd_dim, header_dim)] * 8)\n",
        "value_list = nn.ModuleList([nn.Linear(embd_dim, header_dim)] * 8)\n",
        "\n",
        "q_list = [query(x) for query in query_list]\n",
        "k_list = [key(x) for key in key_list]\n",
        "v_list = [value(x) for value in value_list]\n",
        "\n",
        "x_header_list = list()\n",
        "for n in range(8):\n",
        "    wei = q_list[n] @ k_list[n].transpose(-2, -1)\n",
        "    wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "    wei = F.softmax(wei, dim=-1)\n",
        "    x_header = wei @ v[n]\n",
        "    x_header_list.append(x_header)\n",
        "\n",
        "fc_list = nn.ModuleList([nn.Linear(header_dim, embd_dim)] * 8)\n",
        "\n",
        "x_mht = torch.zeros(8, 16, embd_dim)\n",
        "for n in range(8):\n",
        "    fc = fc_list[n]\n",
        "    x_mht += fc(x_header_list[n])\n",
        "\n",
        "print(x_mht.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_bnFjsFUcFc",
        "outputId": "2b9896e1-066c-4154-f976-06cb27af6c01"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 16, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* 上面这种写法，感觉并行度不够，多头都是串行的。看看标准答案吧，哈哈。\n",
        "* 标准答案思路：Header和MultiHeader 2个类，然后ModuleList 进来，循环过完再cat+proj\n",
        "* 标准答案其实也有串行的部分！另外标准答案里面还有个dropout，这块之前没注意到\n",
        "* 另外还有一个，忘了除以根号d, 原因上节课有讲，是为了保证vars在1.0左右，不至于让softmax太peak变成了hardmax哈哈"
      ],
      "metadata": {
        "id": "6TZlM25qukUw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 思路3，扫了下标准答案后\n",
        "class Header(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.query = nn.Linear(embd_dim, header_dim)\n",
        "        self.key = nn.Linear(embd_dim, header_dim)\n",
        "        self.value = nn.Linear(embd_dim, header_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        q = self.query(x)\n",
        "        k = self.key(x)\n",
        "        v = self.value(x)\n",
        "\n",
        "        wei = q @ k.transpose(-2, -1)\n",
        "\n",
        "        # 标准答案\n",
        "        # wei = q @ k.transpose(-2,-1) * k.shape[-1]**-0.5 # (B, T, hs) @ (B, hs, T) -> (B, T, T)\n",
        "\n",
        "        tril = torch.tril(torch.ones(T, T))\n",
        "        wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "\n",
        "        # 标准答案\n",
        "        # wei = self.dropout(wei)\n",
        "\n",
        "        x_attn = wei @ v\n",
        "\n",
        "        return x_attn\n",
        "\n",
        "class MultiHead(nn.ModuleList):\n",
        "    def __init__(self, headers_num=8):\n",
        "        super().__init__()\n",
        "\n",
        "        self.headers = nn.ModuleList([Header()] * headers_num)\n",
        "        self.proj = nn.Linear(header_dim * headers_num, embd_dim)\n",
        "        # 标准答案\n",
        "        # self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_header_list = [h(x) for h in self.headers] # shape (n, B, T, header_dim)\n",
        "        x_headers_flatten = torch.cat(x_header_list, dim=-1)\n",
        "        x_mha = self.proj(x_headers_flatten)\n",
        "\n",
        "        return x_mha\n",
        "\n",
        "\n",
        "multihead = MultiHead()\n",
        "x_mha = multihead(x)\n",
        "\n",
        "print(x_mha.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xZSjckzxqU5f",
        "outputId": "16cba7d7-a8d2-4609-a202-83bd8331dba1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 16, 256])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用在gpt-mao的代码，对比一下标准答案，有如下分析：\n",
        "1. **参数名更标准：** 标准答案参数名叫c_attn，这个是为了和Transformers库保持一致方便load模型\n",
        "2. **更高效：** 标准答案使用了nn.Linear(config.n_embd, 3 * config.n_embd)，一次搞定qkv。\n",
        "3. **遵循原论文：** shape从(B, T, C) -> (B, T, n_head, C // n_head) 保证了 C = n_head * head_size。 Think: 为啥要保证这个？\n",
        "4. **核心逻辑一致：**  (B, T, n_head, head_size) -> (B, n_head, T, head_size)。Think: 为什么这么处理还是没特别想透"
      ],
      "metadata": {
        "id": "SnXBBH2vV4WQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 思路4:\n",
        "\n",
        "class GPTConfig:\n",
        "    def __init__(self, config):\n",
        "        self.B = config['B']\n",
        "        self.T = config['T']\n",
        "        self.C = config['C']\n",
        "\n",
        "        self.vocab_size = config['vocab_size']\n",
        "\n",
        "        self.header_size = config['header_size']\n",
        "        self.headers_num = config['headers_num']\n",
        "\n",
        "        self.blocks_num = config['blocks_num']\n",
        "        self.ffn_size = config['ffn_size']\n",
        "\n",
        "class MultiHeadV4(nn.Module):\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "\n",
        "        self.key = nn.Linear(config.C, config.header_size * config.headers_num)\n",
        "        self.query = nn.Linear(config.C, config.header_size * config.headers_num)\n",
        "        self.value = nn.Linear(config.C, config.header_size * config.headers_num)\n",
        "        self.attn_fc = nn.Linear(config.header_size * config.headers_num, config.C)\n",
        "\n",
        "\n",
        "    def split_headers(self, x, batch_size):\n",
        "        \"\"\"Split the last dimension into (num_heads, head_dim) and transpose the result.\"\"\"\n",
        "        x = x.view(batch_size, config.T, self.config.headers_num, self.config.header_size)\n",
        "\n",
        "        return x.transpose(1, 2) # shape (B, headers_num, T, header_size) 这里需要thinking一下why\n",
        "\n",
        "    def combine_headers(self, x, batch_size):\n",
        "        \"\"\"\n",
        "            Combine the heads and restore the original last dimension.\n",
        "            x.shape (B, headers_num, T, header_size)\n",
        "        \"\"\"\n",
        "        x = x.transpose(1, 2).contiguous()\n",
        "        # 这里view中的-1，表示自动计算。其实可以直接用T\n",
        "        return x.view(batch_size, self.config.T, self.config.headers_num * self.config.header_size)\n",
        "\n",
        "    def attn(self, x):\n",
        "        \"\"\"\n",
        "        x.shape (B, T, C)\n",
        "        \"\"\"\n",
        "        config = self.config\n",
        "        B, T, C = x.shape\n",
        "\n",
        "        # k, q, v shape (B, headers_num, T, header_size)\n",
        "        k = self.split_headers(self.key(x), B)\n",
        "        q = self.split_headers(self.query(x), B)\n",
        "        v = self.split_headers(self.value(x), B)\n",
        "\n",
        "        tril = torch.tril(torch.ones(config.T, config.T))\n",
        "        wei = q @ k.transpose(-2, -1) # 这个时候用负数的兼容性就体现了\n",
        "        wei = wei.masked_fill(tril == 0, float('-inf'))\n",
        "        wei = wei / (config.header_size ** 0.5)\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        # wei.shape (B, headers_num, T, T)\n",
        "\n",
        "        out = wei @ v # out.shape (B, headers_num, T, header_size)\n",
        "        out = self.combine_headers(out, B)  # out.shape(B, T, config.header_size * config.headers_num)\n",
        "        x = self.attn_fc(out)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.attn(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "config = GPTConfig({'B': B, 'T': T, 'C': embd_dim, 'vocab_size': vocab_size, 'header_size': header_dim, 'headers_num': headers_num, 'blocks_num': 4, 'ffn_size': 256})\n",
        "mha = MultiHeadV4(config)\n",
        "\n",
        "x_mha_v4 = mha(x)\n",
        "print(x_mha_v4.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr1XiwHtQFdO",
        "outputId": "2a32e139-4361-4fec-fc33-fb9b696e7593"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 16, 256])\n"
          ]
        }
      ]
    }
  ]
}